# -*- coding: utf-8 -*-
"""Germen_Street_Sign_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19c_dLtXUNKIXchCdjkhovspsh6OKenvO
"""

# Clone Dataset From Bitbucket
! git clone https://bitbucket.org/jadslim/german-traffic-signs.git

# Dataset isin Pickle Format
# importing Libraries
import pickle
import matplotlib.pyplot as plt
import numpy as np
import cv2
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Conv2D,Flatten,MaxPooling2D,Dense,Dropout
from tensorflow.keras.models import Sequential
from sklearn.metrics import classification_report

# There is three folders in dataset train,test and valid
# Opening Datasets Subfolders
with open('german-traffic-signs/train.p','rb') as f:
  train_data=pickle.load(f)
with open('german-traffic-signs/test.p','rb') as f:
  test_data=pickle.load(f)
with open('german-traffic-signs/valid.p','rb') as f:
  val_data=pickle.load(f)

# In this dataset basically all images is in dictionary 
type(train_data)

# So we have to save features and labels seperately is in x_train and y_train variable 
x_train,y_train=train_data['features'],train_data['labels']
x_test,y_test=test_data['features'],test_data['labels']
x_val,y_val=val_data['features'],val_data['labels']

# Now we are able to read
# Just find shape first
x_train.shape

x_test.shape

x_val.shape

# Now we know how many images in folders and is in which format
plt.imshow(x_train[0])

print(y_train[0])

# Convert images into grayscale for better result
def gray(img):
  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  return img
# equalizing images 
def equalize(img):
  img = cv2.equalizeHist(img)
  return img
# Combining all function and normalizing images
def preprocess(img):
  img = gray(img)
  img = equalize(img)
  img = img/255
  return img

# Its not possible for us to read images one by one so we use map here
x_train = np.array(list(map(preprocess,x_train)))
x_test = np.array(list(map(preprocess,x_test)))
x_val = np.array(list(map(preprocess,x_val)))

# Changing label data into categorical 
y_train=to_categorical(y_train,43)
y_test=to_categorical(y_test,43)
y_val=to_categorical(y_val,43)

# reshape images into gray scale which is 1
x_train=x_train.reshape(34799, 32, 32, 1)
x_test=x_test.reshape(12630, 32, 32, 1)
x_val=x_val.reshape(4410, 32, 32, 1)

print(x_train.shape)
print(x_test.shape)
print(x_val.shape)

# All preprocessing Done lets start building our cnn model
model=Sequential()

model.add(Conv2D(32,(5,5),input_shape=(32,32,1),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(20,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(500,activation='relu'))
model.add(Dropout(0.4))
model.add(Dense(43,activation='softmax'))

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

# Lets fit model
model.fit(x_train,y_train,epochs=20,batch_size=400,verbose=1,shuffle=1)

y_test = np.argmax(y_test,axis=1)

prediction=model.predict_classes(x_test)

model.save('Sign_classifier.h5')

prediction[0]

print(classification_report(prediction,y_test))

"""Congratulation"""



